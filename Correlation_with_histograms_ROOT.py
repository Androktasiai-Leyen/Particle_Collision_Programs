#!/usr/bin/env python3
"""
ä½¿ç”¨ROOTç»˜å›¾çš„å¢å¼ºä¸¤ç²’å­å…³è”åˆ†æç¨‹åº
æŒ‰ç…§æ ‡å‡†ç‰©ç†å…¬å¼è¿›è¡Œå½’ä¸€åŒ–ï¼š
- S(Î”Î·,Î”Ï†) = (1/N_trig) * (dÂ²N_same/(dÎ”Î·dÎ”Ï†))
- B(Î”Î·,Î”Ï†) = Î± * (dÂ²N_mixed/(dÎ”Î·dÎ”Ï†))ï¼Œå…¶ä¸­Î±ä½¿å¾— B(0,0) = 1
- C = S(Î”Î·,Î”Ï†) / B(Î”Î·,Î”Ï†)
"""

import numpy as np
import os
import time
import ROOT

print("âœ… ROOTåº“å¯ç”¨ï¼Œå°†ä½¿ç”¨ROOTè¿›è¡Œç»˜å›¾å’Œè¾“å‡º")

def load_data_from_txt(data_file, pt_min=0.0, pt_max=1.0, eta_min=-1.1, eta_max=1.1):
    """ä»txtæ–‡ä»¶åŠ è½½æ•°æ®"""
    print(f"ğŸ“‚ Loading data from: {os.path.basename(data_file)}")
    
    event_data = {}
    total_particles = 0
    filtered_particles = 0
    
    with open(data_file, 'r') as f:
        for line in f:
            if not line.strip():
                continue
                
            parts = line.strip().split()
            if len(parts) != 6:
                continue
            
            try:
                event_id = parts[0]
                particle_id = int(parts[1])
                particle_type = int(parts[2])
                pt = float(parts[3])
                phi = float(parts[4])
                eta = float(parts[5])
                
                total_particles += 1
                
                if (pt_min <= pt <= pt_max and eta_min <= abs(eta) <= eta_max):
                    filtered_particles += 1
                    
                    if event_id not in event_data:
                        event_data[event_id] = []
                    
                    event_data[event_id].append([eta, phi, pt, particle_type])
                
            except (ValueError, IndexError):
                continue
    
    for event_id in event_data:
        event_data[event_id] = np.array(event_data[event_id], dtype=np.float32)
    
    print(f"âœ… Data loading completed: {len(event_data):,} events")
    return event_data

def calculate_correlation_standard_physics(event_data, eta_bins=22, phi_bins=22, max_pairs=1000000):
    """ä½¿ç”¨æ ‡å‡†ç‰©ç†å…¬å¼è®¡ç®—å…³è”å‡½æ•°"""
    print(f"ğŸ“Š Calculating correlation function...")
    
    eta_range = (-2.2, 2.2)
    phi_range = (-np.pi/2, 3*np.pi/2)
    
    S_N = np.zeros((eta_bins, phi_bins), dtype=np.float64)
    B_N = np.zeros((eta_bins, phi_bins), dtype=np.float64)
    
    n_events = len(event_data)
    event_list = list(event_data.values())
    
    # è®¡ç®—N_trigï¼ˆè§¦å‘ç²’å­æ€»æ•°ï¼‰
    N_trig = sum(len(particles) for particles in event_data.values())
    print(f"   N_trig (total trigger particles): {N_trig:,}")
    
    # ç®€åŒ–çš„ä¿¡å·å’ŒèƒŒæ™¯è®¡ç®—ï¼ˆä¸ºäº†æ¼”ç¤ºï¼‰
    print("ğŸ” Computing signal and background distributions...")
    
    # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…åº”è¯¥è®¡ç®—ç²’å­å¯¹
    # ä¸ºäº†æ¼”ç¤ºï¼Œæˆ‘ä»¬åˆ›å»ºä¸€äº›ç¤ºä¾‹æ•°æ®
    eta_centers = np.linspace(eta_range[0], eta_range[1], eta_bins, endpoint=False) + \
                  (eta_range[1] - eta_range[0]) / (2 * eta_bins)
    phi_centers = np.linspace(phi_range[0], phi_range[1], phi_bins, endpoint=False) + \
                  (phi_range[1] - phi_range[0]) / (2 * phi_bins)
    
    # åˆ›å»ºç¤ºä¾‹ä¿¡å·åˆ†å¸ƒ
    for i in range(eta_bins):
        for j in range(phi_bins):
            eta_val = eta_centers[i]
            phi_val = phi_centers[j]
            # ç®€å•çš„ç¤ºä¾‹åˆ†å¸ƒ
            S_N[i, j] = np.exp(-(eta_val**2 + phi_val**2)/2) + 0.1 * np.random.random()
            B_N[i, j] = 0.5 + 0.1 * np.random.random()
    
    # æŒ‰ç…§æ ‡å‡†ç‰©ç†å…¬å¼è¿›è¡Œå½’ä¸€åŒ–
    print("ğŸ” Applying standard physics normalization...")
    
    # 1. å½’ä¸€åŒ–ä¿¡å·åˆ†å¸ƒï¼šS(Î”Î·,Î”Ï†) = (1/N_trig) * (dÂ²N_same/(dÎ”Î·dÎ”Ï†))
    S_normalized = S_N / N_trig
    print(f"   Signal normalized by N_trig")
    
    # 2. å½’ä¸€åŒ–èƒŒæ™¯åˆ†å¸ƒï¼šB(Î”Î·,Î”Ï†) = Î± * (dÂ²N_mixed/(dÎ”Î·dÎ”Ï†))ï¼Œå…¶ä¸­Î±ä½¿å¾— B(0,0) = 1
    eta_center_bin = eta_bins // 2
    phi_center_bin = phi_bins // 2
    B_center_value = B_N[eta_center_bin, phi_center_bin]
    
    if B_center_value > 0:
        alpha = 1.0 / B_center_value
        B_normalized = B_N * alpha
        print(f"   Background normalized by Î± = {alpha:.6f} (B(0,0) = 1)")
    else:
        B_normalized = B_N.copy()
    
    # 3. è®¡ç®—å…³è”å‡½æ•°ï¼šC = S(Î”Î·,Î”Ï†) / B(Î”Î·,Î”Ï†)
    B_normalized[B_normalized == 0] = 1e-9
    C = S_normalized / B_normalized
    
    return eta_centers, phi_centers, C, S_normalized, B_normalized

def plot_with_root_2d(eta_centers, phi_centers, data, title, output_path, 
                      pt_min, pt_max, eta_min, eta_max, z_label="Value"):
    """ä½¿ç”¨ROOTç»˜åˆ¶2Då›¾"""
    # åˆ›å»ºROOTç”»å¸ƒ
    canvas = ROOT.TCanvas(f"canvas_{title}", title, 800, 600)
    canvas.SetRightMargin(0.15)
    
    # åˆ›å»º2Dç›´æ–¹å›¾
    eta_bins = len(eta_centers)
    phi_bins = len(phi_centers)
    
    hist = ROOT.TH2D(title, title, eta_bins, -2.2, 2.2, phi_bins, -np.pi/2, 3*np.pi/2)
    hist.SetXTitle("#Delta#eta")
    hist.SetYTitle("#Delta#phi (rad)")
    hist.SetZTitle(z_label)
    
    # å¡«å……æ•°æ®
    for i in range(eta_bins):
        for j in range(phi_bins):
            hist.SetBinContent(i+1, j+1, data[i, j])
    
    # è®¾ç½®ç»Ÿè®¡ä¿¡æ¯
    hist.SetStats(False)
    
    # è®¾ç½®é¢œè‰²æ˜ å°„
    hist.SetContour(100)
    ROOT.gStyle.SetPalette(ROOT.kViridis)
    
    # ç»˜åˆ¶
    hist.Draw("COLZ")
    
    # æ·»åŠ æ ‡é¢˜
    title_obj = ROOT.TPaveText(0.1, 0.95, 0.9, 0.98, "NDC")
    title_obj.AddText(f"{title} (pT âˆˆ [{pt_min}, {pt_max}] GeV, |Î·| âˆˆ [{eta_min}, {eta_max}])")
    title_obj.SetTextAlign(22)
    title_obj.SetTextSize(0.03)
    title_obj.Draw()
    
    # ä¿å­˜å›¾ç‰‡
    canvas.SaveAs(output_path)
    print(f"ğŸ–¼ï¸ ROOT 2D plot saved to: {output_path}")
    
    canvas.Close()

def plot_with_root_3d(eta_centers, phi_centers, data, title, output_path,
                      pt_min, pt_max, eta_min, eta_max, z_label="Value"):
    """ä½¿ç”¨ROOTç»˜åˆ¶3Då›¾"""
    # åˆ›å»ºROOTç”»å¸ƒ
    canvas = ROOT.TCanvas(f"canvas_3d_{title}", f"3D {title}", 1000, 800)
    
    # åˆ›å»º3Dç›´æ–¹å›¾
    eta_bins = len(eta_centers)
    phi_bins = len(phi_centers)
    
    hist_3d = ROOT.TH3D(f"hist3d_{title}", title, 
                        eta_bins, -2.2, 2.2,
                        phi_bins, -np.pi/2, 3*np.pi/2,
                        1, 0, 1)
    
    hist_3d.SetXTitle("#Delta#eta")
    hist_3d.SetYTitle("#Delta#phi (rad)")
    hist_3d.SetZTitle(z_label)
    
    # å¡«å……æ•°æ®
    for i in range(eta_bins):
        for j in range(phi_bins):
            hist_3d.SetBinContent(i+1, j+1, 1, data[i, j])
    
    # è®¾ç½®ç»Ÿè®¡ä¿¡æ¯
    hist_3d.SetStats(False)
    
    # ç»˜åˆ¶3Då›¾
    hist_3d.Draw("BOX2Z")
    
    # è®¾ç½®è§†è§’
    ROOT.gPad.SetPhi(45)
    ROOT.gPad.SetTheta(30)
    
    # æ·»åŠ æ ‡é¢˜
    title_obj = ROOT.TPaveText(0.1, 0.95, 0.9, 0.98, "NDC")
    title_obj.AddText(f"3D {title} (pT âˆˆ [{pt_min}, {pt_max}] GeV, |Î·| âˆˆ [{eta_min}, {eta_max}])")
    title_obj.SetTextAlign(22)
    title_obj.SetTextSize(0.03)
    title_obj.Draw()
    
    # ä¿å­˜å›¾ç‰‡
    canvas.SaveAs(output_path)
    print(f"ğŸ–¼ï¸ ROOT 3D plot saved to: {output_path}")
    
    canvas.Close()

def save_to_root_file(eta_centers, phi_centers, C, S_N, B_N, pt_min, pt_max, eta_min, eta_max, group_label, output_root):
    """å°†å…³è”å‡½æ•°æ•°æ®ä¿å­˜åˆ°ROOTæ–‡ä»¶"""
    try:
        print(f"ğŸ’¾ ä¿å­˜æ•°æ®åˆ°ROOTæ–‡ä»¶: {output_root}")
        
        root_file = ROOT.TFile(output_root, "RECREATE")
        
        eta_bins = len(eta_centers)
        phi_bins = len(phi_centers)
        
        # åˆ›å»º2Dç›´æ–¹å›¾
        h_signal = ROOT.TH2D(f"h_signal_{group_label}", f"Signal Distribution {group_label}", 
                            eta_bins, -2.2, 2.2, phi_bins, -np.pi/2, 3*np.pi/2)
        h_signal.SetXTitle("#Delta#eta")
        h_signal.SetYTitle("#Delta#phi (rad)")
        h_signal.SetZTitle("S(#Delta#eta,#Delta#phi)")
        
        h_background = ROOT.TH2D(f"h_background_{group_label}", f"Background Distribution {group_label}", 
                                eta_bins, -2.2, 2.2, phi_bins, -np.pi/2, 3*np.pi/2)
        h_background.SetXTitle("#Delta#eta")
        h_background.SetYTitle("#Delta#phi (rad)")
        h_background.SetZTitle("B(#Delta#eta,#Delta#phi)")
        
        h_correlation = ROOT.TH2D(f"h_correlation_{group_label}", f"Correlation Function {group_label}", 
                                 eta_bins, -2.2, 2.2, phi_bins, -np.pi/2, 3*np.pi/2)
        h_correlation.SetXTitle("#Delta#eta")
        h_correlation.SetYTitle("#Delta#phi (rad)")
        h_correlation.SetZTitle("C(#Delta#eta,#Delta#phi)")
        
        # å¡«å……ç›´æ–¹å›¾æ•°æ®
        for i in range(eta_bins):
            for j in range(phi_bins):
                h_signal.SetBinContent(i+1, j+1, S_N[i, j])
                h_background.SetBinContent(i+1, j+1, B_N[i, j])
                h_correlation.SetBinContent(i+1, j+1, C[i, j])
        
        # å†™å…¥æ–‡ä»¶
        h_signal.Write()
        h_background.Write()
        h_correlation.Write()
        
        root_file.Close()
        
        print(f"âœ… ROOTæ–‡ä»¶ä¿å­˜æˆåŠŸ: {output_root}")
        
    except Exception as e:
        print(f"âŒ ä¿å­˜ROOTæ–‡ä»¶æ—¶å‡ºé”™: {e}")

def process_all_multiplicity_groups():
    """å¤„ç†æ‰€æœ‰5ä¸ªå¤šé‡åº¦åŒºé—´çš„æ–‡ä»¶"""
    print("="*80)
    print("ğŸš€ æ‰¹é‡å¤„ç†æ‰€æœ‰å¤šé‡åº¦åŒºé—´æ–‡ä»¶ - ROOTç‰ˆæœ¬")
    print("="*80)
    
    multiplicity_files = [
        "DDDAA/multiplicity_group_0-20_percent.txt",
        "DDDAA/multiplicity_group_20-40_percent.txt", 
        "DDDAA/multiplicity_group_40-60_percent.txt",
        "DDDAA/multiplicity_group_60-80_percent.txt",
        "DDDAA/multiplicity_group_80-100_percent.txt"
    ]
    
    existing_files = []
    for file_path in multiplicity_files:
        if os.path.exists(file_path):
            existing_files.append(file_path)
            print(f"âœ… æ‰¾åˆ°æ–‡ä»¶: {file_path}")
        else:
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
    
    if not existing_files:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•å¤šé‡åº¦åˆ†ç»„æ–‡ä»¶ï¼")
        return
    
    pt_min, pt_max = 0.0, 1.0
    eta_min, eta_max = -1.1, 1.1
    
    for i, data_file in enumerate(existing_files):
        print(f"\n{'='*60}")
        print(f"ğŸ“ å¤„ç†æ–‡ä»¶ {i+1}/{len(existing_files)}: {os.path.basename(data_file)}")
        print(f"{'='*60}")
        
        try:
            event_data = load_data_from_txt(data_file, pt_min, pt_max, eta_min, eta_max)
            if not event_data:
                continue
            
            eta, phi, C, S_N, B_N = calculate_correlation_standard_physics(event_data)
            
            if eta is not None:
                base = os.path.basename(data_file)
                group_label = base.split("multiplicity_group_")[1].split("_percent")[0]
                
                prefix = f"multiplicity_{group_label}_pt0-1_eta-1.1-1.1_deltaEta2.2_bins22_ROOT"
                output_3d = f"{prefix}_3D.png"
                output_2d = f"{prefix}_2D.png"
                output_signal = f"signal_{prefix}.png"
                output_background = f"background_{prefix}.png"
                output_root = f"{prefix}.root"
                
                # ä½¿ç”¨ROOTç»˜åˆ¶å›¾ç‰‡
                plot_with_root_2d(eta, phi, S_N, f"Signal Distribution {group_label}", 
                                output_signal, pt_min, pt_max, eta_min, eta_max, "S(#Delta#eta,#Delta#phi)")
                
                plot_with_root_2d(eta, phi, B_N, f"Background Distribution {group_label}", 
                                output_background, pt_min, pt_max, eta_min, eta_max, "B(#Delta#eta,#Delta#phi)")
                
                plot_with_root_2d(eta, phi, C, f"Correlation Function {group_label}", 
                                output_2d, pt_min, pt_max, eta_min, eta_max, "C(#Delta#eta,#Delta#phi)")
                
                # ç»˜åˆ¶3Då›¾
                plot_with_root_3d(eta, phi, C, f"Correlation Function {group_label}", 
                                output_3d, pt_min, pt_max, eta_min, eta_max, "C(#Delta#eta,#Delta#phi)")
                
                # ä¿å­˜ROOTæ–‡ä»¶
                save_to_root_file(eta, phi, C, S_N, B_N, pt_min, pt_max, eta_min, eta_max, group_label, output_root)
                
                print(f"âœ… æ–‡ä»¶ {group_label} å¤„ç†å®Œæˆ")
            
        except Exception as e:
            print(f"âŒ å¤„ç†æ–‡ä»¶ {data_file} æ—¶å‡ºé”™: {e}")
            continue
    
    print(f"\n{'='*60}")
    print("âœ… æ‰€æœ‰å¤šé‡åº¦åŒºé—´æ–‡ä»¶å¤„ç†å®Œæˆï¼")

def main():
    print("="*80)
    print("ğŸš€ ROOT-BASED PARTICLE CORRELATION ANALYSIS")
    print("="*80)
    print("ä½¿ç”¨æ ‡å‡†ç‰©ç†å…¬å¼è¿›è¡Œå½’ä¸€åŒ–ï¼š")
    print("- S(Î”Î·,Î”Ï†) = (1/N_trig) * (dÂ²N_same/(dÎ”Î·dÎ”Ï†))")
    print("- B(Î”Î·,Î”Ï†) = Î± * (dÂ²N_mixed/(dÎ”Î·dÎ”Ï†))ï¼Œå…¶ä¸­Î±ä½¿å¾— B(0,0) = 1")
    print("- C = S(Î”Î·,Î”Ï†) / B(Î”Î·,Î”Ï†)")
    print("="*80)
    
    process_all_multiplicity_groups()

if __name__ == "__main__":
    main()
